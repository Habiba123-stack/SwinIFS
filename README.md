# ğŸš€ SwinFSR: Landmark-Guided Swin Transformer for Face Super-Resolution

SwinFSR is a landmark-guided Swin Transformer model designed for **4Ã— and 8Ã— face super-resolution**.  
It integrates facial landmark heatmaps with a hierarchical Swin Transformer to reconstruct identity-consistent high-resolution facial images under severe degradation.

---

## ğŸ”¥ Key Features
- **Landmark-Guided Input:** 8-channel input (RGB + 5 Gaussian landmark heatmaps)  
- **Transformer Backbone:** Swin Transformer with 6 Residual Swin Transformer Blocks (RSTBs)  
- **Multi-Scale SR:** Supports 4Ã— (32â†’128) and 8Ã— (16â†’128)  
- **Identity Preservation:** Strong geometric and structural consistency  
- **Evaluation Metrics:** PSNR (Y), SSIM (Y), LPIPS (RGB)

---

## ğŸ§© Methodology Overview
SwinFSR fuses facial geometry (landmark heatmaps) with transformer-based localâ€“global feature modeling.  
A shallow convolution extracts initial features, and stacked RSTBs enhance facial structure and texture.  
PixelShuffle upsampling reconstructs the high-resolution output.

---

## ğŸ§± Methodology Diagram

---


#ğŸš€ SwinFSR: Landmark-Guided Swin Transformer for Face Super-Resolution

SwinFSR is a landmark-guided Swin Transformer model designed for 4Ã— and 8Ã— face super-resolution.
It integrates dense landmark heatmaps with hierarchical shifted-window attention, enabling accurate reconstruction of identity-consistent facial details even under extreme low-resolution degradation.

---

## ğŸ”¥ Key Features

Landmark-Guided SR: Injects geometric priors using 5-point Gaussian heatmaps

Transformer Backbone: Swin Transformer with 6 Residual Swin Transformer Blocks (RSTBs)

Multiscale SR: Supports 4Ã— (32â†’128) and 8Ã— (16â†’128) upscaling

Identity Preservation: Maintains consistent geometry around eyes, lips & nose

Efficient Training: Lightweight and optimized for single-GPU setups

Evaluation Metrics: PSNR (Y), SSIM (Y), LPIPS (RGB)
---

## ğŸ§© Methodology Overview

SwinFSR fuses facial geometry (landmark heatmaps) with transformer-based localâ€“global modeling.
A shallow 3Ã—3 convolution extracts low-level features, while stacked RSTBs model long-range dependencies and restore fine facial details.
PixelShuffle reconstructs the high-resolution output, supported by a bicubic upsample skip connection for stable identity preservation.

## ğŸ§± Methodology Diagram

## ğŸ–¼ Visual Results
8Ã— Face Super-Resolution (16 â†’ 128)

(You may add 4Ã— results or comparison grids in this section.)

## ğŸ“ Project Structure
SwinFSR/
â”‚â”€â”€ train_swinfsr.py                 # Training + validation
â”‚â”€â”€ test_swinfsr.py                  # Inference/testing (optional)
â”‚â”€â”€ README.md
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ network_swinfsr.py           # SwinFSR architecture
â”‚   â”œâ”€â”€ model_base.py
â”‚   â”œâ”€â”€ model_plain.py
â”‚   â”œâ”€â”€ select_model.py
â”‚   â””â”€â”€ select_network.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset_sr.py                # Loads HR, LR and landmark heatmaps
â”‚   â””â”€â”€ select_dataset.py
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ prep_landmarks.py            # Generate HR crops, LR images & heatmaps
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ utils_image.py
â”‚   â”œâ”€â”€ utils_option.py
â”‚   â”œâ”€â”€ utils_model.py
â”‚   â”œâ”€â”€ utils_logger.py
â”‚   â”œâ”€â”€ utils_dist.py
â”‚   â””â”€â”€ utils_modelsummary.py
â”‚
â”œâ”€â”€ options/
â”‚   â””â”€â”€ swinfsr/
â”‚        â”œâ”€â”€ train_swinfsr_sr_celeba_x4.json
â”‚        â””â”€â”€ train_swinfsr_sr_celeba_x8.json
â”‚
â””â”€â”€ Figures/
    â”œâ”€â”€ Methodology_Research.png
    â””â”€â”€ x8.png

## ğŸ“¦ Dataset Preparation

SwinFSR is trained on CelebA, preprocessed into:

HR images: 128Ã—128

LR images (4Ã—): 32Ã—32

LR images (8Ã—): 16Ã—16

Landmark heatmaps: 5 Gaussian maps per LR image

Generate HR, LR, and landmark heatmaps:

python preprocessing/prep_landmarks.py


This creates:

HR_128x128/train  
HR_128x128/test  
LR/X4/train  
LR/X4/test  
LR/X4_landmarks/train  
LR/X4_landmarks/test  


(and similarly for X8)

## ğŸš€ Training
4Ã— Super-Resolution
python train_swinfsr.py --opt options/swinfsr/train_swinfsr_sr_celeba_x4.json

8Ã— Super-Resolution
python train_swinfsr.py --opt options/swinfsr/train_swinfsr_sr_celeba_x8.json


## Training performs:

Automatic checkpoint saving

Testing at specified intervals

Logging PSNR, SSIM, LPIPS

Automatic bicubic comparison

Optional saving of SR visual outputs

## ğŸ” Testing / Inference
python test_swinfsr.py --opt options/swinfsr/train_swinfsr_sr_celeba_x4.json --save_results


Results are stored in:

results_swinfsr/


You may also test on any custom LR image folder.

## ğŸ“Š Evaluation Metrics

SwinFSR uses standard metrics in the face SR literature:

PSNR (Y-channel)

SSIM (Y-channel)

LPIPS (RGB) using AlexNet backbone

This evaluation protocol follows:

SwinIR (ICCV 2021)

DIC-Net (CVPR 2020)

FSRNet (CVPR 2018)

SPARNet (TIP 2021)

## ğŸ§  Model Architecture Summary

Input: 8 channels (RGB + 5 landmark heatmaps)

Shallow feature extractor: 3Ã—3 Conv

Deep feature extraction: 6 Ã— RSTBs with shifted-window MHSA

Upsampling: PixelShuffle

Reconstruction: 3Ã—3 Conv

Skip connection: Bicubic LR â†’ HR

## ğŸ§ª Results Summary

SwinFSR achieves:

Superior perceptual sharpness

Accurate identity reconstruction

Clear eye, lip, and nose details

Lower LPIPS compared to CNN/GAN/SwinIR baselines

Strong robustness on extreme low-resolution faces

## ğŸ¤ Acknowledgements

SwinFSR builds upon foundational codebases:

KAIR â€” https://github.com/cszn/KAIR

SwinIR â€” https://github.com/JingyunLiang/SwinIR

## ğŸ“ Citation
Shahzad.
â€œSwinFSR: Landmark-Guided Swin Transformer for Identity-Preserving Face Super-Resolution.â€
MS Thesis, 2025.

ğŸ‘¨â€ğŸ’» Author

Shahzad
MS Thesis â€” Landmark-Guided Face Super-Resolution (2025)
